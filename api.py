"""
FastAPI æ¨ç†æœåŠ¡
ä½¿ç”¨ vLLM è¿›è¡Œ Qwen2.5-VL å›¾ç‰‡åˆ†ç±»æ¨ç†
æ”¯æŒä¸Šä¼ æ–‡ä»¶å’ŒOSS URLä¸¤ç§æ–¹å¼
"""

import io
import json
import gc
import os
from pathlib import Path
from typing import List, Optional
from contextlib import asynccontextmanager

import oss2
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from PIL import Image
from pydantic import BaseModel

from vllm import LLM, SamplingParams

# ============ å…¨å±€å˜é‡ ============
llm_engine = None
sampling_params = None
oss_bucket = None  # OSS Bucketå®ä¾‹


# ============ é…ç½® ============
class Config:
    MODEL_PATH = "/data/hx/LLaMA-Factory/output/qwen2_5vl_lora_classify"
    MAX_TOKENS = 32
    TEMPERATURE = 0.0
    GPU_MEMORY_UTILIZATION = 0.9

    # é˜¿é‡Œäº‘OSSé…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    OSS_ACCESS_KEY_ID = os.getenv("OSS_ACCESS_KEY_ID", "")
    OSS_ACCESS_KEY_SECRET = os.getenv("OSS_ACCESS_KEY_SECRET", "")
    # ä½¿ç”¨å†…ç½‘endpointï¼Œä¸èµ°å…¬ç½‘ï¼ŒèŠ‚çœæµé‡è´¹ç”¨å¹¶æé«˜é€Ÿåº¦
    # å†…ç½‘: oss-cn-beijing-internal.aliyuncs.com (åŒåŒºåŸŸECSè®¿é—®)
    # å¤–ç½‘: oss-cn-beijing.aliyuncs.com (å…¬ç½‘è®¿é—®)
    OSS_ENDPOINT = os.getenv("OSS_ENDPOINT", "oss-cn-beijing-internal.aliyuncs.com")
    OSS_BUCKET_NAME = os.getenv("OSS_BUCKET_NAME", "ts-bigdata-chart-prd")

    # æ¨ç†æç¤ºè¯
    PROMPT_TEMPLATE = "è¯·åˆ¤æ–­è¿™å¼ å•†å“å›¾ç‰‡çš„è§’åº¦ç±»åˆ«ã€‚ç±»åˆ«åŒ…æ‹¬ï¼šå…¨èº«æ¨¡ç‰¹ã€å…¶ä»–è§’åº¦ã€å£è¢‹ç‰¹å†™ã€å•†æ ‡ç‰¹å†™ã€æ­£é¢å¹³é“ºã€æ­£é¢æ¨¡ç‰¹ã€èƒŒé¢å¹³é“ºã€èƒŒé¢æ¨¡ç‰¹ã€è…°éƒ¨ç‰¹å†™ã€è£¤è„šç‰¹å†™ã€‚è¯·ç›´æ¥å›ç­”ç±»åˆ«åç§°ã€‚"


# ============ æ•°æ®æ¨¡å‹ ============
class PredictResponse(BaseModel):
    """æ¨ç†å“åº”"""
    image_name: str
    category: str
    confidence: Optional[float] = None


class PredictByOssRequest(BaseModel):
    """é€šè¿‡OSSè·¯å¾„æ¨ç†çš„è¯·æ±‚"""
    object_key: str  # OSSå¯¹è±¡è·¯å¾„ï¼Œå¦‚: products/image001.jpg
    bucket_name: Optional[str] = None  # å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„bucket
    image_name: Optional[str] = None


class BatchPredictByOssRequest(BaseModel):
    """æ‰¹é‡OSSè·¯å¾„æ¨ç†çš„è¯·æ±‚"""
    object_keys: List[str]
    bucket_name: Optional[str] = None


class BatchPredictResponse(BaseModel):
    """æ‰¹é‡æ¨ç†å“åº”"""
    results: List[PredictResponse]
    total: int
    errors: Optional[List[dict]] = None


class HealthResponse(BaseModel):
    """å¥åº·æ£€æŸ¥å“åº”"""
    status: str
    model_loaded: bool
    oss_connected: bool


# ============ è¾…åŠ©å‡½æ•° ============
def prepare_prompt() -> str:
    """å‡†å¤‡æ¨ç†promptï¼ˆQwen2.5-VLå®˜æ–¹æ ¼å¼ï¼‰"""
    prompt = (
        "<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n"
        f"<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>"
        f"{Config.PROMPT_TEMPLATE}<|im_end|>\n"
        "<|im_start|>assistant\n"
    )
    return prompt


def download_image_from_oss(object_key: str, bucket_name: Optional[str] = None) -> Image.Image:
    """
    ä»é˜¿é‡Œäº‘OSSä¸‹è½½å›¾ç‰‡

    Args:
        object_key: OSSå¯¹è±¡è·¯å¾„ï¼Œå¦‚ 'products/image001.jpg'
        bucket_name: bucketåç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„bucket

    Returns:
        PIL.Imageå¯¹è±¡

    Raises:
        HTTPException: ä¸‹è½½å¤±è´¥æˆ–å›¾ç‰‡æ— æ•ˆ
    """
    global oss_bucket

    try:
        # ä½¿ç”¨æŒ‡å®šbucketæˆ–é»˜è®¤bucket
        if bucket_name and bucket_name != Config.OSS_BUCKET_NAME:
            # åˆ›å»ºä¸´æ—¶bucketå¯¹è±¡
            auth = oss2.Auth(Config.OSS_ACCESS_KEY_ID, Config.OSS_ACCESS_KEY_SECRET)
            temp_bucket = oss2.Bucket(auth, Config.OSS_ENDPOINT, bucket_name)
            bucket = temp_bucket
        else:
            bucket = oss_bucket

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not bucket.object_exists(object_key):
            raise HTTPException(
                status_code=404,
                detail=f"OSSæ–‡ä»¶ä¸å­˜åœ¨: {object_key}"
            )

        # ä¸‹è½½æ–‡ä»¶
        result = bucket.get_object(object_key)
        image_data = io.BytesIO(result.read())

        # è½¬æ¢ä¸ºPIL Image
        image = Image.open(image_data)

        # éªŒè¯å›¾ç‰‡
        image.verify()

        # é‡æ–°åŠ è½½ï¼ˆverifyåéœ€è¦é‡æ–°æ‰“å¼€ï¼‰
        image_data.seek(0)
        image = Image.open(image_data)

        return image

    except oss2.exceptions.NoSuchKey:
        raise HTTPException(status_code=404, detail=f"OSSæ–‡ä»¶ä¸å­˜åœ¨: {object_key}")
    except oss2.exceptions.NoSuchBucket:
        raise HTTPException(status_code=404, detail=f"OSS Bucketä¸å­˜åœ¨: {bucket_name}")
    except oss2.exceptions.AccessDenied:
        raise HTTPException(status_code=403, detail="OSSè®¿é—®è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥AccessKeyæƒé™")
    except oss2.exceptions.ServerError as e:
        raise HTTPException(status_code=500, detail=f"OSSæœåŠ¡å™¨é”™è¯¯: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"OSSå›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")


def predict_image(image: Image.Image, prompt: str) -> str:
    """å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œæ¨ç†"""
    global llm_engine, sampling_params

    # ç¡®ä¿å›¾ç‰‡æ˜¯RGBæ¨¡å¼
    if image.mode != "RGB":
        image = image.convert("RGB")

    # ä½¿ç”¨vLLMè¿›è¡Œæ¨ç†
    outputs = llm_engine.generate(
        {
            "prompt": prompt,
            "multi_modal_data": {"image": image},
        },
        sampling_params=sampling_params
    )

    # æå–å“åº”
    response = outputs[0].outputs[0].text.strip()
    return response


# ============ ç”Ÿå‘½å‘¨æœŸç®¡ç† ============
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼šå¯åŠ¨æ—¶åŠ è½½æ¨¡å‹ï¼Œå…³é—­æ—¶æ¸…ç†"""
    global llm_engine, sampling_params, oss_bucket

    print("=" * 60)
    print("ğŸš€ å¯åŠ¨ FastAPI æ¨ç†æœåŠ¡ï¼ˆOSSä¸“ç”¨ç‰ˆï¼‰...")
    print("=" * 60)

    # åˆå§‹åŒ–OSSå®¢æˆ·ç«¯
    try:
        auth = oss2.Auth(Config.OSS_ACCESS_KEY_ID, Config.OSS_ACCESS_KEY_SECRET)
        oss_bucket = oss2.Bucket(auth, Config.OSS_ENDPOINT, Config.OSS_BUCKET_NAME)
        # æµ‹è¯•è¿æ¥
        oss_bucket.get_bucket_info()
        print(f"âœ“ OSSè¿æ¥æˆåŠŸ: {Config.OSS_BUCKET_NAME}")
    except Exception as e:
        print(f"âŒ OSSåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        print("  è¯·æ£€æŸ¥OSSé…ç½®")
        oss_bucket = None

    # åˆå§‹åŒ– vLLM
    print(f"\nâ³ æ­£åœ¨åŠ è½½æ¨¡å‹: {Config.MODEL_PATH}")
    llm_engine = LLM(
        model=Config.MODEL_PATH,
        max_model_len=4096,
        max_num_seqs=5,
        mm_processor_kwargs={
            "min_pixels": 28 * 28,
            "max_pixels": 1280 * 28 * 28,
            "fps": 1,
        },
        limit_mm_per_prompt={"image": 1},
        gpu_memory_utilization=Config.GPU_MEMORY_UTILIZATION,
    )
    print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

    # åˆ›å»ºé‡‡æ ·å‚æ•°
    sampling_params = SamplingParams(
        max_tokens=Config.MAX_TOKENS,
        temperature=Config.TEMPERATURE,
        top_p=1.0,
    )
    print(f"âœ“ é‡‡æ ·å‚æ•°é…ç½®å®Œæˆ (max_tokens={Config.MAX_TOKENS}, temperature={Config.TEMPERATURE})")

    print("\n" + "=" * 60)
    print("âœ… æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
    print("=" * 60)
    print(f"ğŸ“ APIæ–‡æ¡£: http://0.0.0.0:8888/docs")
    print(f"ğŸ“ å¥åº·æ£€æŸ¥: http://0.0.0.0:8888/health")
    print("=" * 60 + "\n")

    yield

    # å…³é—­æ—¶æ¸…ç†
    print("\nğŸ›‘ æ­£åœ¨å…³é—­æœåŠ¡...")
    llm_engine = None
    print("âœ“ æœåŠ¡å·²å…³é—­")


# ============ FastAPI åº”ç”¨ ============
app = FastAPI(
    title="Qwen2.5-VL å›¾ç‰‡åˆ†ç±» API",
    description="åŸºäº vLLM çš„å•†å“å›¾ç‰‡è§’åº¦åˆ†ç±»æ¨ç†æœåŠ¡",
    version="1.0.0",
    lifespan=lifespan
)


# ============ API è·¯ç”± ============
@app.get("/", tags=["Root"])
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "Qwen2.5-VL å›¾ç‰‡åˆ†ç±» API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health"
    }


@app.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return HealthResponse(
        status="healthy" if llm_engine is not None else "loading",
        model_loaded=llm_engine is not None,
        oss_connected=oss_bucket is not None
    )


@app.post("/predict/oss", response_model=PredictResponse, tags=["Inference"])
async def predict_by_oss(request: PredictByOssRequest):
    """
    å•å¼ å›¾ç‰‡æ¨ç†ï¼ˆOSSè·¯å¾„æ–¹å¼ï¼Œæ¨èï¼‰

    - **object_key**: OSSå¯¹è±¡è·¯å¾„ï¼Œå¦‚ 'products/image001.jpg'
    - **bucket_name**: å¯é€‰ï¼Œbucketåç§°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„bucketï¼‰
    - **image_name**: å¯é€‰ï¼Œå›¾ç‰‡åç§°ï¼ˆç”¨äºè¿”å›ç»“æœæ ‡è¯†ï¼‰

    è¿”å›é¢„æµ‹çš„ç±»åˆ«

    ä¼˜åŠ¿ï¼š
    - æ— éœ€ç”Ÿæˆç­¾åURL
    - æ”¯æŒç§æœ‰bucket
    - æ›´å®‰å…¨é«˜æ•ˆ

    ç¤ºä¾‹:
    ```json
    {
        "object_key": "products/image001.jpg",
        "image_name": "äº§å“001"
    }
    ```
    """
    if llm_engine is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹å°šæœªåŠ è½½å®Œæˆï¼Œè¯·ç¨åé‡è¯•")

    if oss_bucket is None:
        raise HTTPException(status_code=503, detail="OSSæœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®")

    pil_image = None
    try:
        # ä»OSSä¸‹è½½å›¾ç‰‡
        pil_image = download_image_from_oss(
            request.object_key,
            request.bucket_name
        )

        # å‡†å¤‡prompt
        prompt = prepare_prompt()

        # æ¨ç†
        result = predict_image(pil_image, prompt)

        # ç¡®å®šå›¾ç‰‡åç§°
        image_name = request.image_name or request.object_key.split('/')[-1]

        return PredictResponse(
            image_name=image_name,
            category=result
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ¨ç†å¤±è´¥: {str(e)}")
    finally:
        # æ˜¾å¼æ¸…ç†å›¾ç‰‡å†…å­˜
        if pil_image is not None:
            try:
                pil_image.close()
            except:
                pass
            del pil_image
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()


@app.post("/predict/batch/oss", response_model=BatchPredictResponse, tags=["Inference"])
async def predict_batch_by_oss(request: BatchPredictByOssRequest):
    """
    æ‰¹é‡å›¾ç‰‡æ¨ç†ï¼ˆOSSè·¯å¾„æ–¹å¼ï¼Œæ¨èï¼‰

    - **object_keys**: OSSå¯¹è±¡è·¯å¾„åˆ—è¡¨
    - **bucket_name**: å¯é€‰ï¼Œbucketåç§°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„bucketï¼‰

    è¿”å›æ‰€æœ‰å›¾ç‰‡çš„é¢„æµ‹ç»“æœï¼ŒåŒ…å«é”™è¯¯ä¿¡æ¯

    ç¤ºä¾‹:
    ```json
    {
        "object_keys": [
            "products/image001.jpg",
            "products/image002.jpg",
            "products/image003.jpg"
        ]
    }
    ```
    """
    if llm_engine is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹å°šæœªåŠ è½½å®Œæˆï¼Œè¯·ç¨åé‡è¯•")

    if oss_bucket is None:
        raise HTTPException(status_code=503, detail="OSSæœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®")

    if len(request.object_keys) == 0:
        raise HTTPException(status_code=400, detail="è¯·è‡³å°‘æä¾›ä¸€ä¸ªOSSå¯¹è±¡è·¯å¾„")

    if len(request.object_keys) > 100:
        raise HTTPException(status_code=400, detail="å•æ¬¡æœ€å¤šæ”¯æŒ100å¼ å›¾ç‰‡")

    try:
        results = []
        errors = []
        prompt = prepare_prompt()

        # é€å¼ å¤„ç†ï¼Œç«‹å³æ¸…ç†å†…å­˜
        for idx, object_key in enumerate(request.object_keys):
            pil_image = None
            try:
                # ä»OSSä¸‹è½½å›¾ç‰‡
                pil_image = download_image_from_oss(
                    object_key,
                    request.bucket_name
                )

                # ç¡®ä¿å›¾ç‰‡æ˜¯RGBæ¨¡å¼
                if pil_image.mode != "RGB":
                    pil_image = pil_image.convert("RGB")

                # å•å¼ æ¨ç†
                result = predict_image(pil_image, prompt)

                # æå–å›¾ç‰‡åç§°
                image_name = object_key.split('/')[-1]

                results.append(PredictResponse(
                    image_name=image_name,
                    category=result
                ))

            except HTTPException as e:
                # è®°å½•é”™è¯¯ï¼Œç»§ç»­å¤„ç†å…¶ä»–å›¾ç‰‡
                errors.append({
                    "object_key": object_key,
                    "error": e.detail
                })
                continue
            except Exception as e:
                errors.append({
                    "object_key": object_key,
                    "error": str(e)
                })
                continue
            finally:
                # ç«‹å³æ¸…ç†å½“å‰å›¾ç‰‡å†…å­˜
                if pil_image is not None:
                    try:
                        pil_image.close()
                    except:
                        pass
                    del pil_image
                    # æ¯10å¼ å›¾ç‰‡å¼ºåˆ¶åƒåœ¾å›æ”¶ä¸€æ¬¡
                    if (idx + 1) % 10 == 0:
                        gc.collect()

        # æœ€ç»ˆåƒåœ¾å›æ”¶
        gc.collect()

        return BatchPredictResponse(
            results=results,
            total=len(results),
            errors=errors if errors else None
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡æ¨ç†å¤±è´¥: {str(e)}")


# ============ é”™è¯¯å¤„ç† ============
@app.exception_handler(404)
async def not_found_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={"detail": "æ¥å£ä¸å­˜åœ¨ï¼Œè¯·æŸ¥çœ‹ /docs è·å–APIæ–‡æ¡£"}
    )


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8888,  # ä¿®æ”¹ä¸º8888ç«¯å£ï¼ˆ8000å·²è¢«å ç”¨ï¼‰
        reload=False,  # ç”Ÿäº§ç¯å¢ƒå…³é—­çƒ­é‡è½½
        log_level="info"
    )
